{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjpqZ6PX-aqx"
   },
   "source": [
    "## This notebook demonstrates how to use object detection models available in [Tensorflow Hub](https://www.tensorflow.org/hub))\n",
    "\n",
    "### This notebook entails:\n",
    "- Exploring Tensorflow Hub for object detection models.\n",
    "- Loading models in your workspace.\n",
    "- Preprocessing an image for inference.\n",
    "- Running inference on the models and inspecting their outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Xub7bGIi-UgC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-18 18:01:25.864548: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-18 18:01:25.864578: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "from six import BytesIO\n",
    "from six.moves.urllib.request import urlopen\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UevoCNAx_r90"
   },
   "source": [
    "## Download the model from `Tensorflow hub`\n",
    "### Tensorflow hub is a repository of trained machine learning models. \n",
    "\n",
    "### We will use the `Inception ResNet v2` model for this demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bPRiamR9_Rym"
   },
   "outputs": [],
   "source": [
    "#Inception ResNet v2.\n",
    "module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "K3Qzgz-2AJQr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "2022-09-18 18:02:32.683876: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-09-18 18:02:32.683943: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-18 18:02:32.684002: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (debonair): /proc/driver/nvidia/version does not exist\n",
      "2022-09-18 18:02:32.684697: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Load the model.\n",
    "model  = hub.load(module_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Ar2mWSKFAPUl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeysView(_SignatureMap({'default': <ConcreteFunction pruned(images) at 0x7FBE7E4D6730>}))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Take a look at the available signatures for this particular model.\n",
    "model.signatures.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oOtP-ICPAYOr"
   },
   "source": [
    "### Choose the `default` signature for your object detector. Its default signature will accept a batch of image tensors and output a dictionary describing the objects detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = model.signatures['default']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download and resize the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_resize_image(url, new_width = 256, new_height = 256):\n",
    "    '''\n",
    "    Fetches an image online, resizes it and saves it locally.\n",
    "    '''\n",
    "    \n",
    "    #Create a temporary file ending with '.jpg'\n",
    "    _, filename = tempfile.mkstemp(suffix = '.jpg')\n",
    "    \n",
    "    #Open the given URL.\n",
    "    response = urlopen(url)\n",
    "    \n",
    "    #Read the image fetched.\n",
    "    image_data = response.read()\n",
    "    \n",
    "    #Puts the image data into the memory buffer.\n",
    "    image_data = BytesIO(image_data)\n",
    "    \n",
    "    #Opens the image.\n",
    "    pil_image = Image.open(image_data)\n",
    "    \n",
    "    #Resizes the image, na cropsit if the aspect ratio is different.\n",
    "    pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n",
    "    \n",
    "    #Converts to RGB colorspace.\n",
    "    pil_image_rgb = pil_image.convert('RGB')\n",
    "    \n",
    "    #Saves the image to a temporary file created earlier.\n",
    "    pil_image_rgb.save(filename, format = 'JPEG', quality = 90)\n",
    "    \n",
    "    print(f'Image downloaded as: {filename}')\n",
    "    \n",
    "    return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download and preprocess the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5508/3769627244.py:22: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image downloaded as: /tmp/tmpuztn08os.jpg\n"
     ]
    }
   ],
   "source": [
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/f/fb/20130807_dublin014.JPG\"\n",
    "\n",
    "\n",
    "#Download the image and use the original height and width.\n",
    "downloaded_image_path = download_and_resize_image(image_url, 3872, 2592)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    '''\n",
    "    Loads the JPEG image and converts it into a tensor.\n",
    "    '''\n",
    "    #Read the file.\n",
    "    img = tf.io.read_file(path)\n",
    "    \n",
    "    #Convert to a tensor.\n",
    "    img = tf.image.decode_jpeg(img, channels = 3)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_detector(detector, path):\n",
    "    '''\n",
    "    Runs inference on a local file using the object detection model.\n",
    "    '''\n",
    "    \n",
    "    #Load the image tensor from a local file path.\n",
    "    img = load_img(path)\n",
    "    \n",
    "    #Add a batch dimension infront of the tensor.\n",
    "    converted_img = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
    "    \n",
    "    #Perform inference using the model.\n",
    "    result = detector(converted_img)\n",
    "    \n",
    "    #Save the resuts in a dictionary.\n",
    "    result = {key: value.numpy() for key, value in result.items()}\n",
    "    \n",
    "    #Print the results.\n",
    "    print(f'Found {len(result[\"detection_scores\"])} objects.')\n",
    "    \n",
    "    print(result['detection_scores'])\n",
    "    print(result['detection_class_entities'])\n",
    "    print(result['detection_boxes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-18 18:04:10.879016: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -2484 } dim { size: -2485 } dim { size: -2486 } dim { size: 1088 } } } inputs { dtype: DT_FLOAT shape { dim { size: -105 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -105 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 17 } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 1800 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -105 } dim { size: 17 } dim { size: 17 } dim { size: 1088 } } }\n",
      "2022-09-18 18:04:38.038988: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 377318400 exceeds 10% of free system memory.\n",
      "2022-09-18 18:04:38.593936: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 377318400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 objects.\n",
      "[0.6544854  0.6114537  0.60422796 0.5926322  0.5921865  0.5804909\n",
      " 0.551406   0.49466905 0.47515708 0.4734224  0.43996006 0.4148515\n",
      " 0.40629673 0.39828914 0.39765224 0.37620997 0.372794   0.36574695\n",
      " 0.3526069  0.33274624 0.30428708 0.27276543 0.26864907 0.2577711\n",
      " 0.25290626 0.24612105 0.23403853 0.20342907 0.1822941  0.18045738\n",
      " 0.17571312 0.16435105 0.15849952 0.1566603  0.15470885 0.15452762\n",
      " 0.14924927 0.13340661 0.12948245 0.12649687 0.12044214 0.11767294\n",
      " 0.11356074 0.11114729 0.11100276 0.10914928 0.10604051 0.08940542\n",
      " 0.08598261 0.08280209 0.08104537 0.07806084 0.07760324 0.07628621\n",
      " 0.07546869 0.07444129 0.07427177 0.07204842 0.07177534 0.07102214\n",
      " 0.07032701 0.06809692 0.06304502 0.06285926 0.06270921 0.0622394\n",
      " 0.05882125 0.0581505  0.05795784 0.05787586 0.05462366 0.05274325\n",
      " 0.05133715 0.04826553 0.0470842  0.04682919 0.04495224 0.04405143\n",
      " 0.0436071  0.04113467 0.04109957 0.03968579 0.03934994 0.03912795\n",
      " 0.03879515 0.03878605 0.03739645 0.03606936 0.03367104 0.0336685\n",
      " 0.03260196 0.03253521 0.03201499 0.02983094 0.02877979 0.02867631\n",
      " 0.02803968 0.02783182 0.0273437  0.02668243]\n",
      "[b'Person' b'Person' b'Person' b'Person' b'Footwear' b'Person' b'Building'\n",
      " b'Bicycle' b'Building' b'Window' b'Person' b'Bicycle' b'Wheel'\n",
      " b'Building' b'Building' b'Building' b'Person' b'Wheel' b'Window'\n",
      " b'Window' b'Building' b'Person' b'Van' b'Person' b'Bicycle wheel'\n",
      " b'Person' b'Window' b'Window' b'Building' b'Window' b'Window' b'Man'\n",
      " b'Person' b'Woman' b'Person' b'Clothing' b'Bicycle wheel' b'Window'\n",
      " b'Person' b'Window' b'Land vehicle' b'Land vehicle' b'Clothing' b'Window'\n",
      " b'Bicycle' b'Land vehicle' b'House' b'House' b'Man' b'Window' b'Clothing'\n",
      " b'Window' b'Footwear' b'Person' b'Man' b'Man' b'House' b'Building'\n",
      " b'Person' b'Clothing' b'Window' b'Person' b'Man' b'Person' b'Furniture'\n",
      " b'Jeans' b'Person' b'Person' b'Person' b'Land vehicle' b'Window' b'House'\n",
      " b'Woman' b'Man' b'Window' b'Person' b'Person' b'Clothing' b'Man' b'Man'\n",
      " b'Window' b'Car' b'Person' b'Man' b'Chair' b'Car' b'House' b'Window'\n",
      " b'Tire' b'Clothing' b'Window' b'Clothing' b'Land vehicle' b'Window'\n",
      " b'Window' b'Man' b'Van' b'Bus' b'Clothing' b'Car']\n",
      "[[5.12794435e-01 5.29270947e-01 6.01662338e-01 5.52094460e-01]\n",
      " [5.19745946e-01 6.01507127e-01 6.46124125e-01 6.34682894e-01]\n",
      " [5.05746007e-01 5.00440776e-01 6.01349175e-01 5.23089647e-01]\n",
      " [4.86308813e-01 4.12762254e-01 6.78550303e-01 4.59905565e-01]\n",
      " [8.15190852e-01 9.56118345e-01 8.42701733e-01 9.87144649e-01]\n",
      " [4.95466530e-01 9.23534274e-01 8.35634887e-01 9.99056876e-01]\n",
      " [1.10985059e-02 1.19119715e-02 7.39750564e-01 4.24907267e-01]\n",
      " [5.77826023e-01 3.66453230e-01 7.12805688e-01 4.83338207e-01]\n",
      " [7.74935707e-02 4.13054019e-01 5.79458833e-01 5.60309231e-01]\n",
      " [0.00000000e+00 1.19292580e-01 2.23897204e-01 1.83949068e-01]\n",
      " [5.14069736e-01 7.48097837e-01 5.91962218e-01 7.66569197e-01]\n",
      " [5.70777893e-01 3.61820370e-01 7.07328379e-01 4.29666817e-01]\n",
      " [6.32094145e-01 3.59869897e-01 7.03841686e-01 4.11815584e-01]\n",
      " [1.59085598e-02 6.84961617e-01 5.59388816e-01 8.11146796e-01]\n",
      " [0.00000000e+00 7.97109306e-01 6.73736036e-01 1.00000000e+00]\n",
      " [0.00000000e+00 2.17026889e-01 6.50973141e-01 4.32000905e-01]\n",
      " [5.00372708e-01 3.77004474e-01 6.33350492e-01 4.14514393e-01]\n",
      " [6.40339971e-01 4.45023417e-01 7.03034759e-01 4.83457506e-01]\n",
      " [1.94404612e-03 0.00000000e+00 1.39331967e-01 2.62884237e-02]\n",
      " [2.55186716e-03 9.66625452e-01 1.53752610e-01 1.00000000e+00]\n",
      " [1.41545618e-03 1.41050143e-03 7.64848292e-01 2.69352019e-01]\n",
      " [5.04901111e-01 3.60784888e-01 6.37663364e-01 3.85480136e-01]\n",
      " [4.83383805e-01 6.19484127e-01 5.62658012e-01 6.61572099e-01]\n",
      " [4.98201460e-01 3.64614099e-01 6.61157489e-01 4.04896408e-01]\n",
      " [6.31229341e-01 3.60322863e-01 7.04147041e-01 4.11499411e-01]\n",
      " [5.21806777e-01 5.77694833e-01 5.87613106e-01 6.00717783e-01]\n",
      " [2.19603732e-01 3.48738879e-01 3.38255525e-01 3.77067655e-01]\n",
      " [1.24826737e-01 2.50923932e-01 2.79914737e-01 2.81625867e-01]\n",
      " [2.57318467e-01 5.67493618e-01 5.30910015e-01 6.87876582e-01]\n",
      " [4.21753526e-02 8.74765277e-01 2.52863407e-01 9.13046181e-01]\n",
      " [1.56401634e-01 4.43365514e-01 2.22233847e-01 4.75784540e-01]\n",
      " [5.01994431e-01 9.21467483e-01 8.36361706e-01 1.00000000e+00]\n",
      " [5.23673594e-01 5.70347011e-01 5.84506154e-01 5.91607034e-01]\n",
      " [5.19169092e-01 5.99965990e-01 6.46330178e-01 6.34094715e-01]\n",
      " [5.13154805e-01 6.79228544e-01 5.50981283e-01 6.92548096e-01]\n",
      " [5.24344563e-01 9.24945474e-01 8.10528219e-01 9.97979462e-01]\n",
      " [6.38063252e-01 4.42797333e-01 7.01729059e-01 4.84131962e-01]\n",
      " [3.41055356e-02 3.55657607e-01 1.62304893e-01 3.74908745e-01]\n",
      " [4.88090277e-01 4.53366935e-01 6.22257173e-01 4.79664922e-01]\n",
      " [9.66504449e-04 3.07707369e-01 1.06515862e-01 3.32070321e-01]\n",
      " [4.82970089e-01 6.19791687e-01 5.64778984e-01 6.60652637e-01]\n",
      " [5.82391143e-01 3.64923388e-01 7.13891625e-01 4.84685332e-01]\n",
      " [5.23790002e-01 7.49292731e-01 5.85470319e-01 7.65311480e-01]\n",
      " [3.51464242e-01 9.74868834e-01 5.53043723e-01 9.98887122e-01]\n",
      " [6.09076977e-01 4.26833510e-01 7.05196321e-01 4.87107515e-01]\n",
      " [5.69254756e-01 3.59783024e-01 7.08566308e-01 4.28438723e-01]\n",
      " [0.00000000e+00 8.11187208e-01 6.93582892e-01 9.93253589e-01]\n",
      " [1.04294838e-02 2.29469202e-02 7.27312565e-01 4.22287613e-01]\n",
      " [4.84632224e-01 4.10697758e-01 6.94742799e-01 4.63139951e-01]\n",
      " [8.11544582e-02 3.84775937e-01 2.07952142e-01 4.11755383e-01]\n",
      " [5.38567245e-01 6.03585005e-01 6.34740770e-01 6.34476542e-01]\n",
      " [0.00000000e+00 1.24075906e-02 1.40296474e-01 2.47341208e-02]\n",
      " [6.29779994e-01 6.14883423e-01 6.44907951e-01 6.25335038e-01]\n",
      " [5.02842903e-01 3.82420689e-01 5.96016228e-01 4.12718713e-01]\n",
      " [5.14681399e-01 7.47871041e-01 5.91947734e-01 7.66782522e-01]\n",
      " [5.06433308e-01 5.00402749e-01 6.00716949e-01 5.23319662e-01]\n",
      " [0.00000000e+00 2.11128622e-01 6.50825918e-01 4.34384257e-01]\n",
      " [0.00000000e+00 7.06320584e-01 6.17161453e-01 8.65940332e-01]\n",
      " [4.89298046e-01 4.54274893e-01 5.72620094e-01 4.76397544e-01]\n",
      " [5.09207368e-01 4.16264892e-01 6.69016659e-01 4.59577173e-01]\n",
      " [4.67803981e-03 8.03107023e-01 1.59582272e-01 8.40365171e-01]\n",
      " [5.26175678e-01 5.68375826e-01 5.79436243e-01 5.82803071e-01]\n",
      " [5.02847552e-01 3.73985916e-01 6.47125900e-01 4.12972599e-01]\n",
      " [4.85917509e-01 4.44437206e-01 6.24690235e-01 4.73519802e-01]\n",
      " [5.74168622e-01 2.67251372e-01 6.57761574e-01 3.20314020e-01]\n",
      " [6.71982288e-01 9.40317750e-01 8.21177125e-01 9.89214003e-01]\n",
      " [5.24104774e-01 5.61555982e-01 5.78347027e-01 5.80502510e-01]\n",
      " [5.17589688e-01 7.57220507e-01 5.88313997e-01 7.71545768e-01]\n",
      " [5.23328543e-01 5.57813823e-01 5.79028904e-01 5.73553503e-01]\n",
      " [6.12360060e-01 4.27401572e-01 7.06096232e-01 4.88300264e-01]\n",
      " [0.00000000e+00 2.44237095e-01 6.08887635e-02 2.93773830e-01]\n",
      " [1.54844159e-02 1.94191094e-03 7.45163381e-01 2.59336591e-01]\n",
      " [4.93266404e-01 9.23959553e-01 8.36913288e-01 9.97706771e-01]\n",
      " [5.05292952e-01 3.60166430e-01 6.43362343e-01 3.91438514e-01]\n",
      " [8.43422953e-03 2.42121428e-01 4.97449487e-02 2.83145577e-01]\n",
      " [5.22109151e-01 5.36088049e-01 5.97674847e-01 5.53133190e-01]\n",
      " [5.13126016e-01 5.23810089e-01 6.00540400e-01 5.42965055e-01]\n",
      " [5.18315673e-01 5.03453434e-01 5.97545326e-01 5.22752881e-01]\n",
      " [5.20455718e-01 6.00931644e-01 6.45991087e-01 6.34363830e-01]\n",
      " [5.13168335e-01 6.79253876e-01 5.50486147e-01 6.92442954e-01]\n",
      " [4.29723203e-01 8.28743577e-01 5.90048730e-01 8.64375412e-01]\n",
      " [5.26593328e-01 6.27190769e-01 5.63289881e-01 6.53785050e-01]\n",
      " [5.04781067e-01 3.89410645e-01 6.15231276e-01 4.19951588e-01]\n",
      " [5.01324892e-01 3.64236265e-01 6.59752846e-01 4.03719962e-01]\n",
      " [5.73110282e-01 2.66732723e-01 6.66223586e-01 3.18649948e-01]\n",
      " [5.15103340e-01 6.24091804e-01 5.63832283e-01 6.58031821e-01]\n",
      " [8.32031742e-02 4.07567918e-01 5.84344089e-01 5.58310449e-01]\n",
      " [2.88201898e-01 4.62553347e-04 4.14279878e-01 3.67076807e-02]\n",
      " [6.27132773e-01 3.60995084e-01 7.05960691e-01 4.09780413e-01]\n",
      " [4.97159481e-01 4.55211073e-01 5.84271312e-01 4.77872074e-01]\n",
      " [1.17194150e-02 3.08072537e-01 9.73200500e-02 3.25075477e-01]\n",
      " [5.15893936e-01 3.80090386e-01 5.96972406e-01 4.11767155e-01]\n",
      " [5.12428999e-01 6.23649299e-01 5.62436640e-01 6.57682240e-01]\n",
      " [4.00773793e-01 8.84974301e-01 5.81656575e-01 9.39130187e-01]\n",
      " [0.00000000e+00 9.94759519e-03 1.36254027e-01 3.15974467e-02]\n",
      " [5.13905644e-01 5.29502392e-01 6.02055967e-01 5.52376091e-01]\n",
      " [5.10691524e-01 6.24039650e-01 5.63410044e-01 6.58179879e-01]\n",
      " [4.80379969e-01 6.20327830e-01 5.65284133e-01 6.60123467e-01]\n",
      " [5.38407385e-01 9.28024292e-01 7.13617265e-01 9.99452710e-01]\n",
      " [4.86337841e-01 6.20247364e-01 5.63528717e-01 6.60217762e-01]]\n"
     ]
    }
   ],
   "source": [
    "run_detector(detector, downloaded_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
